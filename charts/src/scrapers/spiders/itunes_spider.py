#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Copyright (C) 2012 Casey Link <unnamedrambler@gmail.com>
# Copyright (C) 2012 Hugo Lindstr√∂m <hugolm84@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import lxml.html
from lxml import etree
import urllib2
import json
import re
import hashlib
from urlparse import urlparse as urlparser
from os import path
#
#scrapy modules
#
from scrapy.conf import settings
from scrapy import log
from scrapy.spider import BaseSpider
from scrapers.items import SingleTrackItem, SingleAlbumItem, DetailItem, Detail, ChartItem
from sources.utils import cache as chartCache

from countrycode import countrycode

generator_url = 'https://rss.itunes.apple.com/us/'
available_url = 'http://itunes.apple.com/WebObjects/MZStoreServices.woa/wa/RSS/wsAvailableFeeds?cc=%s'

#@chartCache.methodcache.cache('get_countries', expire=settings['ITUNES_EXPIRE'])
def get_countries():
    html_path = path.join(path.dirname(__file__), "itunes_feed_gen.html")
    # generator_url is now loaded dynamically. This is a quick fix...
    doc = lxml.html.parse(html_path)
    e = doc.xpath('.//div[@class="app-controls"]')[0]
    countries = [c.text.encode('utf-8') for c in e.xpath(".//select/option")]
    # Convert country long name to iso2c
    return countrycode(codes=countries, origin='country_name', target='iso2c')

def get_genre(_id):
    return chartCache.storage['itunesgenre_'+_id]

def set_genre(_id, name):
    chartCache.storage['itunesgenre_'+_id] = name

@chartCache.methodcache.cache('get_music_feeds', expire=settings['ITUNES_EXPIRE'])
def get_music_feeds(countries):
    # { name: country, charts: [], genres: [] }
    music_data = []
    for cc in countries:

        url = available_url % (cc)

        log.msg("Getting music feeds for country: %s" % (cc), loglevel=log.INFO)
        try:            
            data = urllib2.urlopen(url).read()
        except Exception,e:
            log.msg("Failed to get feeds for country: %s" % (cc), loglevel=log.WARNING)
            continue;

        # the response has a jsonp callback, lets remove that
        data = data.replace("availableFeeds=", "")
        j = json.loads(data)
        # there are alot of categories, we just want the ones with music
        for cat in j['list']:
            if cat['name'] != "Music" :
                continue
            # returns a list of tuples, where each tuple
            # contains the genre name and numeric id
            genres = [ (g['value'], g['display'] ) for g in cat['genres']['list'] ]
            for g in genres:
                set_genre(g[0], g[1])
            
            # returns a list of tuples, where each tuple
            # contains:
            # url suffix (e.g., 'xml')
            # url prefix
            # name of the feed (e.g, "topalbums")
            # display name of the feed (e.g., "Top Albums")
            # cc is the country id
            charts = [ (c['urlSuffix'], c['urlPrefix'], c['name'], c['display']) for c in cat['types']['list'] ]
            music_data.append( { "country":c, "charts": charts, "genres": genres, "cc" : cc } )
    
    return music_data

def construct_feeds(music_feeds, limit):
    feeds = []
    for item in music_feeds:
        for chart in item['charts']:
            base_url = chart[1]
            suffix = chart[0]
            url = "%s/limit=%s/cc=%s/%s" % (base_url, limit, item['cc'], suffix)
            feeds.append(url)
            for genre in item['genres']:
                g_id = genre[0]
                if len(g_id.strip()) == 0:
                    #sometimes we get blank genres
                    continue
                url = "%s/limit=%s/genre=%s/cc=%s/%s" % (base_url, limit, g_id, item['cc'], suffix)
                feeds.append(url)
    # Only return US new releases
    return filter(lambda url: 'rss.xml' in url and "US" in url or 'rss.xml' not in url, feeds)

def get_feed_urls(limit):
    feeds = construct_feeds(get_music_feeds(get_countries()), limit)
    return feeds

class ItunesSpider(BaseSpider):
    name = 'itunes.com'
    allowed_domains = ['itunes.com']

    start_urls = get_feed_urls(settings['ITUNES_LIMIT'])


    source_id = "itunes"
    source_name = "iTunes"
    description = "Updated daily, browse what currently hot on Itunes. Includes albums, tracks by genre."
    have_extra = True

    details = DetailItem(Detail(
        id = source_id, 
        description = description,
        name = source_name,
        have_extra = have_extra
        )
    );

    def __init__(self, name=None, **kwargs):
        super(ItunesSpider, self).__init__()
        chartCache.shoveDetails(self.details)

    def parse(self, response):
        try:
            feed = etree.fromstring(response.body)
        except etree.XMLSyntaxError:
            log.msg("Parse error, skipping: %s"%(response.url), loglevel=log.WARNING)
            return None
        
        if feed.tag == '{http://www.w3.org/2005/Atom}feed':
            return self.parse_atom(feed)
        elif feed.tag == 'rss':
            return self.parse_rss(feed, response.url)
    
    # Itunes is weird, but that we know. There's sometimes no information about this feed
    # in the response, so we need to construct Title and so forth
    # Also, its sometimes b0rked description filled with bs json
    def parse_rss(self, feed, url):
        genre_name = None
        feed_extra = None
        feed_type = "Album"
        geo = None
        genre = filter(lambda k: 'genre' in k, urlparser(url).path.split("/"))
        try :
            genre_name = get_genre( genre[0].split("=")[1] )
            # geo in xpath is different ISO than in url. We want cc not xpath
            # geo = feed.xpath('.//channel/language')[0].text
            geo_re = re.compile("cc=(.*)(?=\/)")
            rGeo =  geo_re.search(url)
            if rGeo != None:
                geo = rGeo.groups()[0]
        except IndexError :
            return
        
        if 'newreleases' in url :
            feed_extra = "New Album Releases"
        if 'justadded' in url :
            feed_extra = "Just Added Albums"
        if 'featuredalbums' in url:
            feed_extra = "Featured Albums"
        
        if feed_extra is None or genre_name is None or geo is None :
            return
        
        ns = { 'itms': 'http://phobos.apple.com/rss/1.0/modules/itms/' }
        entries = feed.xpath('.//channel/item')
        rank = 0
        chart_list = []
        for entry in entries:
            artist = entry.xpath('itms:artist', namespaces=ns)[0].text
            album = entry.xpath('itms:album', namespaces=ns)[0].text
            rank += 1
            item = SingleAlbumItem()
            item['artist'] = artist
            item['album'] = album
            item['rank'] = rank
            chart_list.append( dict(item) )
        
        chart = ChartItem()
        # Unique ids
        _id = url
        md5 = hashlib.md5()
        md5.update(_id)
        _id = md5.hexdigest()
        
        chart['id'] = _id
        chart['origin'] = url
        chart['genre'] = genre_name
        chart['geo'] = geo.lower()
        chart['name'] = genre_name
        chart['extra'] = feed_extra
        chart["newrls"] = True
        chart['type'] = feed_type
        chart['list'] = chart_list
        chart['source'] = 'itunes'
        # maxage is the last item scraped
        # Expires in 1 days
        expires = chartCache.timedeltaUntilDays(1)
        cacheControl = chartCache.setCacheControl(expires)
        chart['date'] = cacheControl.get("Date-Modified")
        chart['expires'] = cacheControl.get("Date-Expires")
        chart['maxage'] = cacheControl.get("Max-Age")
        
        if _id == settings["ITUNES_DEFAULT_NRCHART"]:
            chart['default'] = 1
        
        return chart
    
    def parse_atom(self, feed):
        ns = {'ns': 'http://www.w3.org/2005/Atom',
            'im': 'http://itunes.apple.com/rss'}
        try:
            _id = feed.xpath('/ns:feed/ns:id', namespaces=ns)[0].text
            _type = feed.xpath('/ns:feed/ns:entry/im:contentType/im:contentType', namespaces=ns)[0].attrib['term']
        except IndexError:
            return

        if _type != "Album" and _type != "Track":
            return # skip playlists

        entries = feed.xpath('/ns:feed/ns:entry', namespaces=ns)
        chart_list = []
        rank = 0
        for entry in entries:
            title = entry.xpath('im:name', namespaces=ns)[0].text
            artist = entry.xpath('im:artist', namespaces=ns)[0].text
            if _type == "Album":
                album = title
                item = SingleAlbumItem()
            elif _type == "Track":
                album = None
                collectionNames = entry.xpath('im:collection/im:name', namespaces=ns)
                if len(collectionNames) > 0:
                    album = collectionNames[0].text
                item = SingleTrackItem()
                item['track'] = title
            
            rank += 1
            item['artist'] = artist
            item['album'] = album
            item['rank'] = rank
            chart_list.append( dict(item) )

        title = feed.xpath('ns:title', namespaces=ns)[0].text

        geo = None
        geo_re = re.compile("cc=([a-zA-Z]+)")
        rGeo =  geo_re.search(_id)
        if rGeo != None:
            geo = rGeo.groups()[0]

        genre = None
        genre_re = re.compile("genre=(\d+)/")
        rGenre =  genre_re.search(_id)
        if rGenre != None:
            genre = rGenre.groups()[0]

        if not genre is None:
            genre = get_genre(genre)

        origin = _id
        md5 = hashlib.md5()
        md5.update(_id)
        _id = md5.hexdigest()

        if geo is None:
            geo_s = origin.split("/")
            geo = geo_s

        chart = ChartItem()
        # Itunes expires tomorrow at 00am
        chart['id'] = _id
        chart['display_name'] = genre if genre else "Top Overall"
        chart['origin'] = origin
        chart['genre'] = genre
        chart['geo'] = geo
        chart['name'] = title
        chart['type'] = _type
        chart['list'] = chart_list
        chart['source'] = 'itunes'

        # maxage is the last item scraped
        expires = chartCache.timedeltaUntilDays(1)
        cacheControl = chartCache.setCacheControl(expires)
        chart['date'] = cacheControl.get("Date-Modified")
        chart['expires'] = cacheControl.get("Date-Expires")
        chart['maxage'] = cacheControl.get("Max-Age")

        if(_id == settings["ITUNES_DEFAULT_ALBUMCHART"] or _id == settings["ITUNES_DEFAULT_TRACKCHART"]):
            print "Found default" + _id
            chart['default'] = 1

        return chart
